"""X/Twitter æ¨æ–‡è½¬å‘è„šæœ¬ï¼ˆåŸºäº RSSHubï¼‰ã€‚

åŠŸèƒ½:
- é€šè¿‡ RSSHub è·å–æŒ‡å®šç”¨æˆ·æœ€æ–°æ¨æ–‡ï¼Œæ— éœ€å®˜æ–¹ APIã€‚
- ä¿å­˜æœ€åå‘é€çš„æ¨æ–‡ IDï¼Œé¿å…é‡å¤é€šçŸ¥ã€‚
- å›¾ç‰‡: å‘é€ Telegram å›¾ç‰‡æˆ–å›¾ç‰‡ç»„ï¼›è§†é¢‘/è½¬æ¨: åªå‘é€æ–‡æœ¬+åŸé“¾æ¥ã€‚

ç¯å¢ƒå˜é‡ï¼ˆ.env æˆ– CI secretsï¼‰:
- GOAL_USERNAME: ç›®æ ‡ç”¨æˆ·åï¼ˆä¸å« @ï¼‰ï¼Œç”¨äºæ ¼å¼åŒ–æ˜¾ç¤ºã€‚
- X_RSS_URL: RSSHub é“¾æ¥ï¼Œä¾‹å¦‚ https://rsshub-kurrna.fly.dev/twitter/user/<username>
- TG_TOKEN_2: Telegram Bot Tokenï¼ˆç”¨äºæœ¬è„šæœ¬ï¼‰
- TG_CHAT_ID: Telegram Chat IDï¼ˆæ¥æ”¶é€šçŸ¥çš„èŠå¤©ï¼‰
"""
from __future__ import annotations

import os
import pathlib
import re
import sys
import time
import json
import html
import hashlib
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import List, Optional, Dict, Any
from zoneinfo import ZoneInfo
from urllib.parse import urlparse
import xml.etree.ElementTree as ET

import requests
from dotenv import load_dotenv


ROOT = pathlib.Path(__file__).resolve().parents[1]
load_dotenv(ROOT / ".env")

GOAL_USERNAME = os.getenv("GOAL_USERNAME", "")
X_RSS_URL = os.getenv("X_RSS_URL", "")
TG_TOKEN = os.getenv("TG_TOKEN_2", "")
TG_CHAT_ID = os.getenv("TG_CHAT_ID", "")

DATA_DIR = ROOT / "messages" / "x_monitor"
LAST_TWEET_FILE = DATA_DIR / "last_tweet_id.txt"
STATE_FILE = DATA_DIR / "state.json"
ARCHIVE_DIR = DATA_DIR / "archive"


@dataclass
class Tweet:
    id: str
    text: str
    url: str
    images: List[str] = field(default_factory=list)
    videos: List[str] = field(default_factory=list)
    timestamp: Optional[str] = None
    is_retweet: bool = False


def ensure_data_dir() -> None:
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)


def load_last_id() -> Optional[str]:
    if LAST_TWEET_FILE.exists():
        v = LAST_TWEET_FILE.read_text(encoding="utf-8").strip()
        return v or None
    return None


def save_last_id(tid: str) -> None:
    ensure_data_dir()
    LAST_TWEET_FILE.write_text(tid, encoding="utf-8")


def load_state() -> Dict[str, Any]:
    if STATE_FILE.exists():
        try:
            return json.loads(STATE_FILE.read_text(encoding="utf-8"))
        except Exception:
            return {}
    return {}


def save_state(state: Dict[str, Any]) -> None:
    ensure_data_dir()
    STATE_FILE.write_text(json.dumps(state, ensure_ascii=False, indent=2), encoding="utf-8")


def content_hash(tweet: Tweet) -> str:
    base = "||".join([
        tweet.text,
        "|".join(tweet.images),
        "|".join(tweet.videos),
    ])
    return hashlib.sha256(base.encode("utf-8", errors="ignore")).hexdigest()

def fetch_rss(url: str, retries: int = 3, backoff: float = 2.0) -> str:
    if not url:
        raise RuntimeError("X_RSS_URL æœªé…ç½®")
    final_url = url
    last_err = None
    headers = {"User-Agent": "Mozilla/5.0"}
    for i in range(retries):
        try:
            resp = requests.get(final_url, headers=headers, timeout=20)
            if resp.status_code == 200 and resp.text.strip():
                return resp.text
            last_err = RuntimeError(f"HTTP {resp.status_code}")
        except Exception as e:
            last_err = e
        time.sleep(backoff)
    raise RuntimeError(f"RSS è·å–å¤±è´¥: {last_err}")


def parse_rss(content: str) -> List[Tweet]:
    tweets: List[Tweet] = []
    try:
        root = ET.fromstring(content)
    except Exception as e:
        raise RuntimeError(f"RSS è§£æå¤±è´¥: {e}")

    for item in root.findall(".//item"):
        link = _get_text(item, "link") or ""
        guid = _get_text(item, "guid") or ""
        tid = _extract_tweet_id(link) or _extract_tweet_id(guid)
        if not tid:
            continue

        title = _get_text(item, "title") or ""
        desc = _get_text(item, "description") or ""
        desc = html.unescape(desc)
        # å–æ›´é•¿çš„æ–‡æœ¬ï¼ˆtitle æœ‰æ—¶è¢«æˆªæ–­ï¼‰
        base_text = title if len(title) >= len(desc) else desc
        pub_date = _get_text(item, "pubDate")

        images, videos = _extract_media(desc)
        text = _clean_text(base_text)
        is_retweet = text.startswith("RT @") or "è½¬æ¨" in text[:10]

        tweet = Tweet(
            id=tid,
            text=text,
            url=link or f"https://x.com/{GOAL_USERNAME}/status/{tid}",
            images=images,
            videos=videos,
            timestamp=pub_date,
            is_retweet=is_retweet,
        )
        tweets.append(tweet)

    return tweets


def _get_text(item: ET.Element, tag: str) -> Optional[str]:
    el = item.find(tag)
    if el is not None and el.text:
        return el.text.strip()
    return None


def _extract_tweet_id(url: str) -> Optional[str]:
    m = re.search(r"/status/(\d+)", url)
    return m.group(1) if m else None


def _extract_media(desc: str) -> tuple[List[str], List[str]]:
    images: List[str] = []
    videos: List[str] = []
    # img æ ‡ç­¾
    for m in re.finditer(r"<img[^>]+src=['\"]([^'\"]+)['\"]", desc, re.IGNORECASE):
        images.append(m.group(1))
    # mp4 é“¾æ¥
    for m in re.finditer(r"https?://[^\s\"]+\.mp4", desc):
        videos.append(m.group(0))
    return images, videos


def _clean_text(text: str) -> str:
    text = re.sub(r"<[^>]+>", "", text)
    text = text.replace("&amp;", "&")
    return text.strip()


def _escape_md(text: str) -> str:
    # ç®€å•è½¬ä¹‰ Markdown ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…æˆªæ–­
    for ch in ["_", "*", "`", "[", "]"]:
        text = text.replace(ch, f"\\{ch}")
    return text


def format_jst_now() -> str:
    jst = ZoneInfo("Asia/Tokyo")
    now = datetime.now(jst)
    return now.strftime("%Y/%m/%d %H:%M:%S JST")


# Telegram å‘é€å‡½æ•°
def send_text(msg: str) -> bool:
    if not TG_TOKEN or not TG_CHAT_ID:
        print("æœªé…ç½® TG_TOKEN_2 æˆ– TG_CHAT_ID")
        return False
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    payload = {"chat_id": TG_CHAT_ID, "text": msg, "parse_mode": "Markdown", "disable_web_page_preview": False}
    try:
        r = requests.post(url, json=payload, timeout=15)
        ok = r.ok and r.json().get("ok")
        if not ok:
            print(f"å‘é€æ–‡æœ¬å¤±è´¥: {r.text}")
        return bool(ok)
    except Exception as e:
        print(f"å‘é€æ–‡æœ¬å¼‚å¸¸: {e}")
        return False


def send_photo(photo_url: str, caption: str = "") -> bool:
    if not TG_TOKEN or not TG_CHAT_ID:
        return False
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendPhoto"
    payload = {"chat_id": TG_CHAT_ID, "photo": photo_url, "caption": caption[:1024], "parse_mode": "Markdown"}
    try:
        r = requests.post(url, json=payload, timeout=30)
        ok = r.ok and r.json().get("ok")
        if not ok:
            print(f"å‘é€å›¾ç‰‡å¤±è´¥: {r.text}")
        return bool(ok)
    except Exception as e:
        print(f"å‘é€å›¾ç‰‡å¼‚å¸¸: {e}")
        return False


def send_media_group(imgs: List[str], caption: str = "") -> bool:
    if not imgs:
        return False
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMediaGroup"
    media = []
    for i, img in enumerate(imgs[:10]):  # Telegram é™åˆ¶ 10 å¼ 
        item = {"type": "photo", "media": img}
        if i == 0 and caption:
            item["caption"] = caption[:1024]
            item["parse_mode"] = "Markdown"
        media.append(item)
    payload = {"chat_id": TG_CHAT_ID, "media": media}
    try:
        r = requests.post(url, json=payload, timeout=60)
        ok = r.ok and r.json().get("ok")
        if not ok:
            print(f"å‘é€å›¾ç‰‡ç»„å¤±è´¥: {r.text}")
        return bool(ok)
    except Exception as e:
        print(f"å‘é€å›¾ç‰‡ç»„å¼‚å¸¸: {e}")
        return False


def write_archive(tweet: Tweet, status: str, now_iso: str) -> None:
    """å°†æ¨æ–‡ä¿å­˜åˆ°æœ¬åœ°å­˜æ¡£ä»¥é˜²è¢«åˆ é™¤/ç¼–è¾‘"""
    ensure_data_dir()
    fname = ARCHIVE_DIR / f"{tweet.id}.md"
    lines = [
        f"# {status} {tweet.id}",
        "",
        f"æ—¶é—´: {now_iso}",
        f"é“¾æ¥: {tweet.url}",
        "",
        tweet.text,
        "",
    ]
    if tweet.images:
        lines.append("å›¾ç‰‡:")
        lines.extend(tweet.images)
        lines.append("")
    if tweet.videos:
        lines.append("è§†é¢‘:")
        lines.extend(tweet.videos)
        lines.append("")
    fname.write_text("\n".join(lines), encoding="utf-8")


def format_message(tweet: Tweet) -> str:
    user = GOAL_USERNAME or "user"
    lines = []
    if tweet.is_retweet:
        lines.append(f"ğŸ” *@{user}* è½¬æ¨")
    else:
        lines.append(f"ğŸ¦ *@{user}* å‘å¸ƒæ–°æ¨æ–‡")
    lines.append("")
    safe_text = _escape_md(tweet.text)
    lines.append(safe_text)
    lines.append("")
    lines.append(f"ğŸ”— [æŸ¥çœ‹åŸæ¨]({tweet.url})")
    if tweet.timestamp:
        lines.append(f"â° {tweet.timestamp}")
    lines.append(f"ğŸ•“ {format_jst_now()}")
    if tweet.videos:
        for v in tweet.videos:
            lines.append(f"ğŸ {v}")
    return "\n".join(lines)


def notify(tweet: Tweet) -> bool:
    msg = format_message(tweet)
    ok_text = send_text(msg)
    # è§†é¢‘æˆ–è½¬æ¨ï¼šåªå‘æ–‡æœ¬å³å¯
    if tweet.is_retweet or tweet.videos:
        return ok_text
    # å›¾ç‰‡ï¼šæ–‡æœ¬ä¹‹åè¡¥å‘å›¾ç‰‡ï¼ˆä¸å¸¦ captionï¼Œé¿å…æˆªæ–­æ–‡æœ¬ï¼‰
    if tweet.images:
        if len(tweet.images) == 1:
            send_photo(tweet.images[0], "")
        else:
            send_media_group(tweet.images, "")
    return ok_text


def check_and_send() -> int:
    if not X_RSS_URL:
        print("é”™è¯¯ï¼šæœªé…ç½® X_RSS_URL")
        return 1
    if not TG_TOKEN or not TG_CHAT_ID:
        print("é”™è¯¯ï¼šæœªé…ç½® TG_TOKEN_2 æˆ– TG_CHAT_ID")
        return 1

    ensure_data_dir()

    try:
        content = fetch_rss(X_RSS_URL)
        tweets = parse_rss(content)
    except Exception as e:
        print(f"æ‹‰å–æˆ–è§£æå¤±è´¥: {e}")
        return 1

    if not tweets:
        print("æœªè·å–åˆ°æ¨æ–‡")
        return 0

    # å½“å‰æ—¶é—´
    now_iso = datetime.now(timezone.utc).replace(microsecond=0).isoformat()

    # è½½å…¥å†å²çŠ¶æ€
    state = load_state()
    last_id_file = load_last_id()

    current_ids = set()
    notifications = []  # (tweet, status)

    for t in tweets:
        current_ids.add(t.id)
        h = content_hash(t)
        rec = state.get(t.id)
        if rec is None:
            # æ–°æ¨æ–‡
            notifications.append((t, "new"))
            state[t.id] = {
                "hash": h,
                "text": t.text,
                "images": t.images,
                "videos": t.videos,
                "url": t.url,
                "first_seen": now_iso,
                "last_seen": now_iso,
                "missing_streak": 0,
                "deleted": False,
            }
        else:
            # å·²å­˜åœ¨ï¼Œæ£€æŸ¥ç¼–è¾‘
            if rec.get("hash") != h:
                notifications.append((t, "edited"))
            state[t.id].update({
                "hash": h,
                "text": t.text,
                "images": t.images,
                "videos": t.videos,
                "url": t.url,
                "last_seen": now_iso,
                "missing_streak": 0,
                "deleted": False,
            })

    # æ£€æµ‹å¯èƒ½åˆ é™¤çš„æ¨æ–‡ï¼šæœªå‡ºç°åœ¨å½“å‰åˆ—è¡¨çš„å†å²æ¨æ–‡
    for tid, rec in list(state.items()):
        if tid in current_ids:
            continue
        if rec.get("deleted"):
            continue
        rec["missing_streak"] = rec.get("missing_streak", 0) + 1
        # è¿ç»­ç¼ºå¤± 3 æ¬¡è®¤ä¸ºè¢«åˆ é™¤
        if rec["missing_streak"] >= 3:
            rec["deleted"] = True
            rec["last_seen"] = now_iso
            # æ„é€ è™šæ‹Ÿ Tweet ç”¨äºé€šçŸ¥
            t = Tweet(
                id=tid,
                text=rec.get("text", "(å†…å®¹å·²å­˜æ¡£)"),
                url=rec.get("url", ""),
                images=rec.get("images", []),
                videos=rec.get("videos", []),
                timestamp=rec.get("last_seen"),
                is_retweet=False,
            )
            notifications.append((t, "deleted"))
        state[tid] = rec

    # æŒ‰ ID æ’åºï¼Œé¿å…ä¹±åº
    notifications.sort(key=lambda x: int(x[0].id) if x[0].id else 0)

    # å‘é€é€šçŸ¥
    sent = 0
    for t, status in notifications:
        print(f"é€šçŸ¥ {status}: {t.id}")
        header = {
            "new": "ğŸ†• æ–°æ¨æ–‡",
            "edited": "âœï¸ æ¨æ–‡å·²ç¼–è¾‘",
            "deleted": "âŒ æ¨æ–‡å¯èƒ½å·²åˆ é™¤",
        }.get(status, "ğŸ†• æ–°æ¨æ–‡")
        # åœ¨æ–‡æœ¬å‰åŠ çŠ¶æ€å¤´
        orig_text = t.text
        t.text = f"{header}\n\n{orig_text}"
        if notify(t):
            sent += 1
        # å†™å­˜æ¡£
        write_archive(t, status, now_iso)
        # æ›´æ–° last_tweet_id æ–‡ä»¶
        save_last_id(t.id)
        time.sleep(1)

    # ä¿å­˜çŠ¶æ€
    save_state(state)

    print(f"å‘é€å®Œæˆ: {sent}/{len(notifications)}")
    return 0


def main() -> int:
    return check_and_send()


if __name__ == "__main__":
    sys.exit(main())
